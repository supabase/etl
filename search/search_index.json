{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"ETL","text":"<p>Stream Postgres changes anywhere, in real-time</p> <p>ETL is a Rust framework for building change data capture (CDC) pipelines on Postgres. Stream inserts, updates, and deletes to BigQuery, Apache Iceberg, or your own custom destinations.</p>"},{"location":"#start-here","title":"Start Here","text":"Your background Recommended path New to Postgres logical replication Postgres Replication Concepts Ready to build Your First Pipeline (15 min) Need custom destinations Custom Stores and Destinations (30 min) Setting up Postgres Configure Postgres"},{"location":"#why-etl","title":"Why ETL?","text":"<ul> <li>Real-time: Changes stream as they happen, not in batches</li> <li>Reliable: At-least-once delivery with automatic retries</li> <li>Extensible: Implement one trait to add any destination</li> <li>Fast: Parallel initial copy, configurable batching</li> <li>Type-safe: Rust API with compile-time guarantees</li> </ul>"},{"location":"#how-it-works","title":"How It Works","text":"<ol> <li>Initial copy: ETL copies existing table data to your destination</li> <li>Streaming: ETL streams events (Insert, Update, Delete, and more) in real-time</li> <li>Recovery: The store persists state so pipelines resume after restarts</li> </ol> <p>See Architecture for details.</p>"},{"location":"#quick-example","title":"Quick Example","text":"<p>Add ETL to your project:</p> <pre><code>[dependencies]\netl = { git = \"https://github.com/supabase/etl\" }\ntokio = { version = \"1.0\", features = [\"full\"] }\n</code></pre> <p>Create a pipeline:</p> <pre><code>use etl::{\n    config::{BatchConfig, PgConnectionConfig, PipelineConfig, TlsConfig},\n    pipeline::Pipeline,\n    store::both::memory::MemoryStore,\n};\nuse etl_destinations::bigquery::BigQueryDestination;\n\n#[tokio::main]\nasync fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {\n    let pg_config = PgConnectionConfig {\n        host: \"localhost\".to_string(),\n        port: 5432,\n        name: \"mydb\".to_string(),\n        username: \"postgres\".to_string(),\n        password: Some(\"password\".to_string().into()),\n        tls: TlsConfig { enabled: false, trusted_root_certs: String::new() },\n        keepalive: None,\n    };\n\n    let config = PipelineConfig {\n        id: 1,\n        publication_name: \"my_publication\".to_string(),\n        pg_connection: pg_config,\n        batch: BatchConfig { max_size: 1000, max_fill_ms: 5000 },\n        table_error_retry_delay_ms: 10_000,\n        table_error_retry_max_attempts: 5,\n        max_table_sync_workers: 4,\n    };\n\n    let store = MemoryStore::new();\n    let destination = BigQueryDestination::new_with_key_path(\n        \"my-gcp-project\".into(),\n        \"my_dataset\".into(),\n        \"/path/to/service-account-key.json\",\n        None,\n        1,\n        1,\n        store.clone(),\n    )\n    .await?;\n\n    let mut pipeline = Pipeline::new(config, store, destination);\n    pipeline.start().await?;\n    pipeline.wait().await?;\n\n    Ok(())\n}\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"Section What you'll find Guides Step-by-step instructions to get things done Explanations Deep dives into concepts and architecture"},{"location":"#contributing","title":"Contributing","text":"<p>Pull requests and issues welcome on GitHub.</p> <p>New destinations: Open an issue first to gauge interest. Each built-in destination carries long-term maintenance cost, so we only accept those with significant community demand.</p>"},{"location":"explanation/","title":"Explanations","text":"<p>Understand how ETL works and why</p>"},{"location":"explanation/#where-to-start","title":"Where to Start","text":"<p>New to Postgres logical replication? Start with Postgres Replication Concepts. It explains WAL, publications, replication slots, and why ETL works the way it does.</p> <p>Already familiar with replication? Jump to Architecture to understand ETL's two-phase approach and delivery guarantees.</p>"},{"location":"explanation/#all-topics","title":"All Topics","text":"<ol> <li> <p>Postgres Replication Concepts: The fundamentals - WAL, publications, slots, pgoutput, and why two phases.</p> </li> <li> <p>Architecture: How ETL works - initial copy, streaming, workers, and delivery guarantees.</p> </li> <li> <p>Event Types: All events your destination receives - Insert, Update, Delete, Begin, Commit, and their fields.</p> </li> <li> <p>Extension Points: The traits you implement - Destination, SchemaStore, StateStore, CleanupStore.</p> </li> </ol>"},{"location":"explanation/#next-steps","title":"Next Steps","text":"<p>When you're ready to build, head to the Guides.</p>"},{"location":"explanation/architecture/","title":"ETL Architecture","text":"<p>How ETL replicates data from Postgres to your destinations</p> <p>ETL uses Postgres logical replication to stream database changes in real-time.</p>"},{"location":"explanation/architecture/#overview","title":"Overview","text":"<pre><code>flowchart LR\n    subgraph Postgres\n        WAL[\"WAL + Publication\"]\n    end\n\n    subgraph Pipeline\n        Apply[\"Apply Worker\"]\n        Sync[\"Table Sync Workers\"]\n    end\n\n    subgraph Storage\n        Store[\"Store&lt;br&gt;(State + Schema)\"]\n    end\n\n    subgraph Target\n        Dest[\"Destination&lt;br&gt;(BigQuery, Iceberg, Custom)\"]\n    end\n\n    WAL --&gt; Apply\n    Apply --&gt; Sync\n    Apply --&gt; Dest\n    Sync --&gt; Dest\n    Apply --&gt; Store\n    Sync --&gt; Store</code></pre>"},{"location":"explanation/architecture/#how-it-works","title":"How It Works","text":"<p>ETL operates in two phases:</p>"},{"location":"explanation/architecture/#phase-1-initial-copy","title":"Phase 1: Initial Copy","text":"<p>When a pipeline starts, it copies all existing data from each table in the publication. Multiple Table Sync Workers run in parallel to copy tables concurrently. Each worker:</p> <ol> <li>Creates a replication slot to capture a consistent snapshot</li> <li>Copies all rows using Postgres <code>COPY</code></li> <li>Sends rows to the destination via <code>write_table_rows()</code></li> </ol> <p>Note: During this phase, <code>Begin</code> and <code>Commit</code> events may be delivered multiple times because workers consume slots in parallel. This is expected and does not cause data duplication - only transaction markers are repeated.</p>"},{"location":"explanation/architecture/#phase-2-continuous-replication","title":"Phase 2: Continuous Replication","text":"<p>Once tables are copied, the Apply Worker streams ongoing changes from the Postgres WAL. It:</p> <ol> <li>Receives change events (inserts, updates, deletes)</li> <li>Batches events for efficiency</li> <li>Sends batches to the destination via <code>write_events()</code></li> </ol>"},{"location":"explanation/architecture/#core-components","title":"Core Components","text":""},{"location":"explanation/architecture/#pipeline","title":"Pipeline","text":"<p>The central orchestrator that manages the entire replication process. It spawns workers, coordinates state transitions, and handles shutdown.</p>"},{"location":"explanation/architecture/#destination","title":"Destination","text":"<p>Where replicated data goes. Implement the <code>Destination</code> trait to send data anywhere:</p> <pre><code>pub trait Destination {\n    fn name() -&gt; &amp;'static str;\n    fn truncate_table(&amp;self, table_id: TableId) -&gt; impl Future&lt;Output = EtlResult&lt;()&gt;&gt; + Send;\n    fn write_table_rows(&amp;self, table_id: TableId, rows: Vec&lt;TableRow&gt;) -&gt; impl Future&lt;Output = EtlResult&lt;()&gt;&gt; + Send;\n    fn write_events(&amp;self, events: Vec&lt;Event&gt;) -&gt; impl Future&lt;Output = EtlResult&lt;()&gt;&gt; + Send;\n}\n</code></pre> Method When called Purpose <code>name()</code> On initialization Identify the destination <code>truncate_table()</code> Before initial copy Clear destination table <code>write_table_rows()</code> During initial copy Receive bulk rows <code>write_events()</code> After initial copy Receive streaming changes"},{"location":"explanation/architecture/#store","title":"Store","text":"<p>Persists pipeline state so replication can resume after restarts. Three traits work together:</p> <ul> <li>StateStore: Tracks replication phase per table and source-to-destination table mappings</li> <li>SchemaStore: Stores table schema information (columns, types, primary keys)</li> <li>CleanupStore: Removes stored state when a table is dropped from the publication</li> </ul> <p><code>StateStore</code> and <code>SchemaStore</code> use a cache-first pattern: reads hit an in-memory cache, writes go to both the cache and persistent storage.</p>"},{"location":"explanation/architecture/#delivery-guarantees","title":"Delivery Guarantees","text":"<p>ETL provides at-least-once delivery. If restarts occur, some events may be delivered more than once. This is a deliberate design choice.</p>"},{"location":"explanation/architecture/#why-not-exactly-once","title":"Why Not Exactly-Once?","text":"<p>Exactly-once delivery requires distributed transactions between Postgres and the destination, adding complexity and latency. Instead, ETL optimizes for throughput and simplicity while minimizing duplicates through:</p> <ul> <li>Controlled shutdown: The pipeline gracefully drains in-flight events before stopping</li> <li>Frequent status updates: Progress is reported to Postgres regularly, reducing the replay window after restarts</li> </ul>"},{"location":"explanation/architecture/#handling-duplicates","title":"Handling Duplicates","text":"<p>Destinations should use primary keys to deduplicate. When writing to the destination, upsert on the primary key instead of inserting - duplicates naturally overwrite with the same data.</p> <p>The <code>start_lsn</code> and <code>commit_lsn</code> fields on events are useful for ordering and checkpointing. For example, BigQuery destinations use these to maintain correct event order in destination tables. See Event Types for details on LSN semantics.</p>"},{"location":"explanation/architecture/#table-replication-phases","title":"Table Replication Phases","text":"<p>Each table progresses through these phases:</p> Phase Set By Description Init Pipeline Table discovered, ready for initial copy DataSync Table Sync Worker Initial table copy in progress FinishedCopy Table Sync Worker Initial copy complete SyncWait Table Sync Worker Waiting for Apply Worker to pause (in-memory only) Catchup Apply Worker Apply Worker paused; Table Sync Worker catching up to its LSN (in-memory only) SyncDone Table Sync Worker Catch-up complete, ready for handoff Ready Apply Worker Apply Worker now handles this table exclusively Errored Either Error occurred; contains reason, solution hint, and retry policy"},{"location":"explanation/architecture/#next-steps","title":"Next Steps","text":"<ul> <li>Extension Points: Implement custom stores and destinations</li> <li>Event Types: Understand event data</li> <li>First Pipeline: Build something</li> <li>Configure Postgres: Database setup</li> </ul>"},{"location":"explanation/concepts/","title":"Postgres Logical Replication Concepts","text":"<p>Essential background for understanding how ETL works</p> <p>This page explains the Postgres concepts that ETL builds on. If you're new to logical replication, read this first.</p>"},{"location":"explanation/concepts/#what-is-logical-replication","title":"What is Logical Replication?","text":"<p>Postgres supports two types of replication:</p> Type What it copies Use case Physical Exact byte-for-byte copy of data files Disaster recovery, read replicas Logical Decoded row changes (INSERT, UPDATE, DELETE) Data integration, ETL, CDC <p>Physical replication creates identical Postgres instances. Logical replication decodes changes into a format that any system can consume - not just another Postgres server.</p> <p>ETL uses logical replication to stream changes to destinations like BigQuery, Iceberg, or your custom systems.</p>"},{"location":"explanation/concepts/#the-write-ahead-log-wal","title":"The Write-Ahead Log (WAL)","text":"<p>Before Postgres modifies data on disk, it first writes the change to the Write-Ahead Log (WAL). This guarantees durability - if Postgres crashes, it can replay the WAL to recover.</p> <pre><code>flowchart LR\n    A[Transaction commits] --&gt; B[Written to WAL] --&gt; C[Later flushed to data files]</code></pre> <p>For logical replication, Postgres decodes the WAL back into logical changes:</p> <pre><code>flowchart LR\n    A[WAL bytes] --&gt; B[\"Decoder (pgoutput)\"] --&gt; C[INSERT/UPDATE/DELETE events]</code></pre> <p>ETL receives these decoded events and forwards them to your destination.</p>"},{"location":"explanation/concepts/#wal-level","title":"WAL Level","text":"<p>Postgres must be configured to record enough information for logical decoding:</p> <pre><code># In postgresql.conf\nwal_level = logical\n</code></pre> <p>With <code>wal_level = logical</code>, Postgres records additional metadata needed to reconstruct row changes. Lower levels (<code>replica</code>, <code>minimal</code>) don't capture enough detail.</p>"},{"location":"explanation/concepts/#publications","title":"Publications","text":"<p>A publication defines which tables to replicate. Think of it as a filter that says \"replicate changes from these tables.\"</p> <pre><code>-- Replicate specific tables\nCREATE PUBLICATION my_publication FOR TABLE users, orders;\n\n-- Replicate all tables (use with caution)\nCREATE PUBLICATION my_publication FOR ALL TABLES;\n</code></pre> <p>When you create an ETL pipeline, you specify which publication to consume. Only changes to tables in that publication are streamed.</p>"},{"location":"explanation/concepts/#what-publications-control","title":"What Publications Control","text":"<ul> <li>Which tables: Only tables in the publication are replicated</li> <li>Which operations: You can filter to only INSERT, UPDATE, or DELETE</li> <li>Which columns (Postgres 15+): Replicate only specific columns</li> <li>Which rows (Postgres 15+): Filter rows with a WHERE clause</li> </ul>"},{"location":"explanation/concepts/#replication-slots","title":"Replication Slots","text":"<p>A replication slot is a bookmark that tracks how far a consumer has read in the WAL.</p>"},{"location":"explanation/concepts/#why-slots-exist","title":"Why Slots Exist","text":"<p>Without slots, Postgres would delete old WAL files when it no longer needs them for crash recovery. But if ETL disconnects temporarily, it needs those WAL files to catch up when it reconnects.</p> <p>Replication slots tell Postgres: \"Don't delete WAL files until this consumer has processed them.\"</p> <pre><code>-- View existing slots\nSELECT slot_name, confirmed_flush_lsn, active\nFROM pg_replication_slots;\n</code></pre>"},{"location":"explanation/concepts/#how-etl-uses-slots","title":"How ETL Uses Slots","text":"<p>ETL creates replication slots automatically:</p> Slot Purpose <code>supabase_etl_apply_{pipeline_id}</code> Main streaming slot for ongoing changes <code>supabase_etl_table_sync_{pipeline_id}_{table_id}</code> Temporary slots for initial table copy <p>The Apply Worker uses one persistent slot. Table Sync Workers create temporary slots during initial copy, then delete them.</p>"},{"location":"explanation/concepts/#slot-risks","title":"Slot Risks","text":"<p>Slots prevent WAL cleanup. If ETL stops consuming (due to crashes, network issues, or a slow destination), WAL files accumulate on disk. This can fill your disk.</p> <p>To mitigate this risk:</p> <ul> <li>Monitor slot lag with <code>pg_replication_slots</code></li> <li>Set <code>max_slot_wal_keep_size</code> to limit WAL retention</li> <li>Alert when slots fall behind</li> </ul> <p>See Configure Postgres for details.</p>"},{"location":"explanation/concepts/#the-pgoutput-decoder","title":"The pgoutput Decoder","text":"<p>When Postgres decodes WAL for logical replication, it uses a decoder plugin. ETL uses <code>pgoutput</code>, Postgres's built-in decoder.</p> <p>The decoder transforms binary WAL records into structured messages:</p> Message Meaning <code>BEGIN</code> Transaction started <code>RELATION</code> Table schema (columns, types) <code>INSERT</code> Row added <code>UPDATE</code> Row modified <code>DELETE</code> Row removed <code>TRUNCATE</code> Table cleared <code>COMMIT</code> Transaction completed <p>ETL receives these messages and converts them to events for your destination.</p>"},{"location":"explanation/concepts/#why-two-phases","title":"Why Two Phases?","text":"<p>ETL replicates data in two phases:</p>"},{"location":"explanation/concepts/#phase-1-initial-copy","title":"Phase 1: Initial Copy","text":"<p>Logical replication only captures changes. It doesn't know about data that existed before replication started.</p> <p>So ETL first copies all existing rows using Postgres's <code>COPY</code> command:</p> <ol> <li>Create replication slot (captures consistent snapshot point)</li> <li>COPY all rows from table to destination</li> <li>Start streaming changes from the snapshot point</li> </ol> <p>The slot ensures no changes are lost between the snapshot and when streaming begins.</p>"},{"location":"explanation/concepts/#phase-2-streaming","title":"Phase 2: Streaming","text":"<p>After initial copy, ETL streams ongoing changes in real-time:</p> <pre><code>flowchart LR\n    A[Postgres WAL] --&gt; B[Decoder] --&gt; C[ETL] --&gt; D[Destination]</code></pre> <p>Each change is delivered as an event (Insert, Update, Delete) to your destination's <code>write_events()</code> method.</p>"},{"location":"explanation/concepts/#why-this-matters","title":"Why This Matters","text":"<p>Understanding the two phases helps you:</p> <ul> <li>Know that initial copy can take time for large tables</li> <li>Understand why <code>write_table_rows()</code> and <code>write_events()</code> are separate methods</li> <li>Debug issues where data exists but changes aren't appearing (or vice versa)</li> </ul>"},{"location":"explanation/concepts/#replica-identity","title":"REPLICA IDENTITY","text":"<p>REPLICA IDENTITY controls what data Postgres includes in UPDATE and DELETE events.</p>"},{"location":"explanation/concepts/#the-problem","title":"The Problem","text":"<p>When a row is updated or deleted, what identifies which row changed? By default, Postgres only sends the primary key - enough to identify the row, but not to see the old values.</p>"},{"location":"explanation/concepts/#settings","title":"Settings","text":"<pre><code>-- See current setting (d=default, f=full, n=nothing, i=index)\nSELECT relname, relreplident FROM pg_class WHERE relname = 'your_table';\n\n-- Change setting\nALTER TABLE your_table REPLICA IDENTITY FULL;\n</code></pre> Setting What's sent with UPDATE/DELETE Use case <code>DEFAULT</code> Primary key columns only Most cases <code>FULL</code> All columns (old values) Audit logs, CDC requiring old values <code>NOTHING</code> Nothing Not recommended <code>USING INDEX</code> Columns from specified index Tables without primary key"},{"location":"explanation/concepts/#impact-on-etl","title":"Impact on ETL","text":"<p>In your destination's <code>write_events()</code>, Update and Delete events have an <code>old_table_row</code> field of type <code>Option&lt;(bool, TableRow)&gt;</code>:</p> <ul> <li>With <code>DEFAULT</code>: Contains <code>Some((true, row))</code> where <code>row</code> has only primary key columns</li> <li>With <code>FULL</code>: Contains <code>Some((false, row))</code> where <code>row</code> has all columns with previous values</li> <li>With <code>NOTHING</code>: Contains <code>None</code></li> </ul> <p>If you need old values for auditing or comparison, set <code>REPLICA IDENTITY FULL</code> on those tables.</p>"},{"location":"explanation/concepts/#lsn-log-sequence-number","title":"LSN (Log Sequence Number)","text":"<p>Every position in the WAL has a unique LSN - a monotonically increasing pointer.</p> <pre><code>Format: 0/16B3748 (segment/offset)\n</code></pre>"},{"location":"explanation/concepts/#lsns-in-events","title":"LSNs in Events","text":"<p>ETL events include two LSN fields:</p> Field Meaning <code>start_lsn</code> Where this event was recorded in the WAL <code>commit_lsn</code> LSN of the commit message in the WAL <p>Multiple events in the same transaction share the same <code>commit_lsn</code> but have different <code>start_lsn</code> values.</p>"},{"location":"explanation/concepts/#why-persist-state","title":"Why Persist State?","text":"<p>ETL persists replication state (schemas, progress, mappings) for recovery.</p>"},{"location":"explanation/concepts/#without-persistence","title":"Without Persistence","text":"<p>If ETL crashes and has no state:</p> <ul> <li>It doesn't know which tables were already copied</li> <li>It doesn't know where in the WAL to resume</li> <li>It would have to start from scratch, potentially duplicating data</li> </ul>"},{"location":"explanation/concepts/#with-persistence","title":"With Persistence","text":"<p>ETL stores:</p> State Purpose Replication phase Know whether to copy or stream for each table Table schemas Validate incoming data against expected schema Table mappings Route events to correct destination tables <p>On restart, ETL loads this state and resumes from where it left off.</p> <p>The built-in <code>PostgresStore</code> persists to your Postgres database. <code>MemoryStore</code> is for testing only - state is lost on restart.</p>"},{"location":"explanation/concepts/#putting-it-together","title":"Putting It Together","text":"<p>Here's the complete flow:</p> <ol> <li>You configure Postgres (<code>wal_level=logical</code>)</li> <li>You create a publication for tables you want to replicate</li> <li>ETL creates a replication slot to track progress</li> <li>ETL copies existing data (Phase 1: Initial Copy)</li> <li>ETL streams ongoing changes (Phase 2: Streaming)</li> <li>Postgres decodes WAL using pgoutput</li> <li>ETL receives events and sends them to your destination</li> <li>ETL reports progress back to Postgres (so WAL can be cleaned up)</li> <li>State is persisted for crash recovery</li> </ol>"},{"location":"explanation/concepts/#next-steps","title":"Next Steps","text":"<ul> <li>Architecture: How ETL's components work together</li> <li>Event Types: All events your destination receives</li> <li>Configure Postgres: Production setup</li> <li>First Pipeline: Build something</li> </ul>"},{"location":"explanation/events/","title":"Event Types","text":"<p>Understanding the events ETL delivers to your destination</p> <p>ETL streams events from Postgres logical replication to your destination via <code>write_events()</code>. This page documents all event types and how to handle them.</p>"},{"location":"explanation/events/#event-overview","title":"Event Overview","text":"Event Description Has Table ID <code>Begin</code> Transaction start No <code>Commit</code> Transaction end No <code>Insert</code> New row added Yes <code>Update</code> Row modified Yes <code>Delete</code> Row removed Yes <code>Relation</code> Table schema Yes <code>Truncate</code> Table cleared Yes <code>Unsupported</code> Unknown event No"},{"location":"explanation/events/#data-modification-events","title":"Data Modification Events","text":"<p>These events carry row data and are associated with specific tables.</p>"},{"location":"explanation/events/#insert","title":"Insert","text":"<p>A new row was added to a table.</p> <pre><code>pub struct InsertEvent {\n    pub start_lsn: PgLsn,      // Position where event was recorded\n    pub commit_lsn: PgLsn,     // Position where transaction commits\n    pub table_id: TableId,     // Which table\n    pub table_row: TableRow,   // The new row data\n}\n</code></pre>"},{"location":"explanation/events/#update","title":"Update","text":"<p>An existing row was modified.</p> <pre><code>pub struct UpdateEvent {\n    pub start_lsn: PgLsn,\n    pub commit_lsn: PgLsn,\n    pub table_id: TableId,\n    pub table_row: TableRow,                     // New row data\n    pub old_table_row: Option&lt;(bool, TableRow)&gt;, // Previous row (see below)\n}\n</code></pre> <p>The <code>old_table_row</code> field depends on Postgres <code>REPLICA IDENTITY</code> setting:</p> REPLICA IDENTITY <code>old_table_row</code> contains <code>DEFAULT</code> Primary key columns only (<code>true</code>, row) <code>FULL</code> All columns (<code>false</code>, row) <code>NOTHING</code> <code>None</code>"},{"location":"explanation/events/#delete","title":"Delete","text":"<p>A row was removed from a table.</p> <pre><code>pub struct DeleteEvent {\n    pub start_lsn: PgLsn,\n    pub commit_lsn: PgLsn,\n    pub table_id: TableId,                       // Which table\n    pub old_table_row: Option&lt;(bool, TableRow)&gt;, // Deleted row data\n}\n</code></pre> <p>Same <code>REPLICA IDENTITY</code> rules apply as for Update.</p>"},{"location":"explanation/events/#truncate","title":"Truncate","text":"<p>One or more tables were truncated (all rows deleted).</p> <pre><code>pub struct TruncateEvent {\n    pub start_lsn: PgLsn,\n    pub commit_lsn: PgLsn,\n    pub options: i8,       // Postgres truncate options\n    pub rel_ids: Vec&lt;u32&gt;, // List of truncated table IDs\n}\n</code></pre> <p>Note: A single Truncate event can affect multiple tables when using <code>TRUNCATE ... CASCADE</code>.</p>"},{"location":"explanation/events/#transaction-events","title":"Transaction Events","text":"<p>These events mark transaction boundaries.</p>"},{"location":"explanation/events/#begin","title":"Begin","text":"<p>Marks the start of a transaction.</p> <pre><code>pub struct BeginEvent {\n    pub start_lsn: PgLsn,   // Position where transaction started\n    pub commit_lsn: PgLsn,  // Position where transaction will commit\n    pub timestamp: i64,     // Transaction start time\n    pub xid: u32,           // Transaction ID\n}\n</code></pre>"},{"location":"explanation/events/#commit","title":"Commit","text":"<p>Marks successful transaction completion.</p> <pre><code>pub struct CommitEvent {\n    pub start_lsn: PgLsn,\n    pub commit_lsn: PgLsn,\n    pub flags: i8,        // Postgres commit flags\n    pub end_lsn: u64,     // Final LSN after commit\n    pub timestamp: i64,   // Commit time\n}\n</code></pre>"},{"location":"explanation/events/#schema-events","title":"Schema Events","text":""},{"location":"explanation/events/#relation","title":"Relation","text":"<p>Provides table schema information. Sent before data events for a table.</p> <pre><code>pub struct RelationEvent {\n    pub start_lsn: PgLsn,\n    pub commit_lsn: PgLsn,\n    pub table_schema: TableSchema, // Column definitions, types, etc.\n}\n</code></pre>"},{"location":"explanation/events/#begincommit-behavior","title":"Begin/Commit Behavior","text":"<p>During initial copy, <code>Begin</code> and <code>Commit</code> events may be delivered multiple times due to parallel Table Sync Workers creating separate replication slots. Row data (Insert, Update, Delete) is delivered exactly once.</p> <p>Handle this by either: - Tracking LSNs to detect duplicate Begin/Commit events - Ignoring Begin/Commit if your destination does not require transactions</p> <pre><code>async fn write_events(&amp;self, events: Vec&lt;Event&gt;) -&gt; EtlResult&lt;()&gt; {\n    for event in events {\n        match event {\n            Event::Insert(e) =&gt; self.handle_insert(e).await?,\n            Event::Update(e) =&gt; self.handle_update(e).await?,\n            Event::Delete(e) =&gt; self.handle_delete(e).await?,\n            Event::Truncate(e) =&gt; self.handle_truncate(e).await?,\n            Event::Relation(e) =&gt; self.handle_schema(e).await?,\n            // Transaction markers - safe to ignore for most destinations\n            Event::Begin(_) | Event::Commit(_) =&gt; {}\n            Event::Unsupported =&gt; {}\n        }\n    }\n    Ok(())\n}\n</code></pre>"},{"location":"explanation/events/#understanding-lsn-fields","title":"Understanding LSN Fields","text":"<p>Every event includes two LSN (Log Sequence Number) fields that are critical for understanding event ordering and deduplication.</p>"},{"location":"explanation/events/#what-is-an-lsn","title":"What is an LSN?","text":"<p>An LSN is a pointer to a position in Postgres's Write-Ahead Log (WAL). It's a monotonically increasing 64-bit integer that uniquely identifies a location in the transaction log. Format: <code>0/16B3748</code> (segment/offset).</p>"},{"location":"explanation/events/#start_lsn-vs-commit_lsn","title":"start_lsn vs commit_lsn","text":"Field Meaning Use Case <code>start_lsn</code> Position where this event was recorded in the WAL Deduplication, ordering within transaction <code>commit_lsn</code> Position where the transaction will commit Transaction grouping, recovery checkpoints <p>Key insight: Multiple events share the same <code>commit_lsn</code> (same transaction) but each has a unique <code>start_lsn</code>.</p>"},{"location":"explanation/events/#example","title":"Example","text":"<p>Consider a transaction that inserts two rows:</p> <pre><code>BEGIN;                    -- Transaction starts\nINSERT INTO users ...;    -- start_lsn: 0/16B3700, commit_lsn: 0/16B3800\nINSERT INTO users ...;    -- start_lsn: 0/16B3750, commit_lsn: 0/16B3800\nCOMMIT;                   -- Transaction commits at 0/16B3800\n</code></pre> <p>Both inserts have the same <code>commit_lsn</code> (they commit together) but different <code>start_lsn</code> values (they're distinct events).</p>"},{"location":"explanation/events/#using-lsns","title":"Using LSNs","text":"<p>For ordering: Events are delivered in <code>start_lsn</code> order within a transaction, and transactions are ordered by <code>commit_lsn</code>.</p> <p>For deduplication: If you see the same <code>start_lsn</code> twice, it's a duplicate event (can happen with Begin/Commit during initial copy).</p> <p>For checkpointing: Store the highest <code>commit_lsn</code> you've processed. On restart, you can resume from that point.</p>"},{"location":"explanation/events/#event-batching","title":"Event Batching","text":"<p>ETL batches events before calling <code>write_events()</code>. A batch may contain events from multiple tables, multiple transactions, and mixed event types.</p> <p>Ordering requirement: Events affecting the same row (by primary key) must be processed in order. Events for different rows can be processed concurrently.</p>"},{"location":"explanation/events/#next-steps","title":"Next Steps","text":"<ul> <li>Custom Destinations: Implement your own event handling</li> <li>Architecture: How events flow through ETL</li> </ul>"},{"location":"explanation/traits/","title":"Extension Points","text":"<p>Traits you implement to customize ETL behavior</p> <p>ETL provides four traits for customization. Implement these to control where data goes and how state is stored.</p>"},{"location":"explanation/traits/#destination","title":"Destination","text":"<p>Receives replicated data. This is the primary extension point for sending data to custom systems.</p> <pre><code>pub trait Destination {\n    fn name() -&gt; &amp;'static str;\n    fn shutdown(&amp;self) -&gt; impl Future&lt;Output = EtlResult&lt;()&gt;&gt; + Send { async { Ok(()) } }\n    fn truncate_table(&amp;self, table_id: TableId) -&gt; impl Future&lt;Output = EtlResult&lt;()&gt;&gt; + Send;\n    fn write_table_rows(&amp;self, table_id: TableId, table_rows: Vec&lt;TableRow&gt;) -&gt; impl Future&lt;Output = EtlResult&lt;()&gt;&gt; + Send;\n    fn write_events(&amp;self, events: Vec&lt;Event&gt;) -&gt; impl Future&lt;Output = EtlResult&lt;()&gt;&gt; + Send;\n}\n</code></pre>"},{"location":"explanation/traits/#methods","title":"Methods","text":"Method Purpose <code>name()</code> Returns identifier for logging and diagnostics <code>shutdown()</code> Called when the pipeline shuts down. Default is a no-op. Override for cleanup or bookkeeping <code>truncate_table()</code> Clears table data before initial sync. Called unconditionally, even if the table does not exist <code>write_table_rows()</code> Writes rows during initial table copy. May receive an empty vector for tables with no data <code>write_events()</code> Processes streaming replication events (inserts, updates, deletes). Batches may span multiple tables"},{"location":"explanation/traits/#implementation-notes","title":"Implementation Notes","text":"<ul> <li>Operations should be idempotent when possible (ETL may retry on failure)</li> <li>Handle concurrent calls safely (parallel table sync workers)</li> <li>Process events in order to maintain data consistency</li> </ul> <p>See Event Types for details on the events received by <code>write_events()</code>.</p>"},{"location":"explanation/traits/#schemastore","title":"SchemaStore","text":"<p>Stores table schema information (column names, types, primary keys).</p> <pre><code>pub trait SchemaStore {\n    fn get_table_schema(&amp;self, table_id: &amp;TableId) -&gt; impl Future&lt;Output = EtlResult&lt;Option&lt;Arc&lt;TableSchema&gt;&gt;&gt;&gt; + Send;\n    fn get_table_schemas(&amp;self) -&gt; impl Future&lt;Output = EtlResult&lt;Vec&lt;Arc&lt;TableSchema&gt;&gt;&gt;&gt; + Send;\n    fn load_table_schemas(&amp;self) -&gt; impl Future&lt;Output = EtlResult&lt;usize&gt;&gt; + Send;\n    fn store_table_schema(&amp;self, table_schema: TableSchema) -&gt; impl Future&lt;Output = EtlResult&lt;()&gt;&gt; + Send;\n}\n</code></pre>"},{"location":"explanation/traits/#methods_1","title":"Methods","text":"Method Purpose <code>get_table_schema()</code> Returns schema for a table from cache. Does not load from persistent storage <code>get_table_schemas()</code> Returns all cached schemas <code>load_table_schemas()</code> Loads schemas from persistent storage into cache. Call once at startup. Returns the number of schemas loaded <code>store_table_schema()</code> Saves schema to both cache and persistent storage"},{"location":"explanation/traits/#statestore","title":"StateStore","text":"<p>Tracks replication progress and table mappings.</p> <pre><code>pub trait StateStore {\n    // Replication state\n    fn get_table_replication_state(&amp;self, table_id: TableId) -&gt; impl Future&lt;Output = EtlResult&lt;Option&lt;TableReplicationPhase&gt;&gt;&gt; + Send;\n    fn get_table_replication_states(&amp;self) -&gt; impl Future&lt;Output = EtlResult&lt;HashMap&lt;TableId, TableReplicationPhase&gt;&gt;&gt; + Send;\n    fn load_table_replication_states(&amp;self) -&gt; impl Future&lt;Output = EtlResult&lt;usize&gt;&gt; + Send;\n    fn update_table_replication_state(&amp;self, table_id: TableId, state: TableReplicationPhase) -&gt; impl Future&lt;Output = EtlResult&lt;()&gt;&gt; + Send;\n    fn rollback_table_replication_state(&amp;self, table_id: TableId) -&gt; impl Future&lt;Output = EtlResult&lt;TableReplicationPhase&gt;&gt; + Send;\n\n    // Table mappings\n    fn get_table_mapping(&amp;self, source_table_id: &amp;TableId) -&gt; impl Future&lt;Output = EtlResult&lt;Option&lt;String&gt;&gt;&gt; + Send;\n    fn get_table_mappings(&amp;self) -&gt; impl Future&lt;Output = EtlResult&lt;HashMap&lt;TableId, String&gt;&gt;&gt; + Send;\n    fn load_table_mappings(&amp;self) -&gt; impl Future&lt;Output = EtlResult&lt;usize&gt;&gt; + Send;\n    fn store_table_mapping(&amp;self, source_table_id: TableId, destination_table_id: String) -&gt; impl Future&lt;Output = EtlResult&lt;()&gt;&gt; + Send;\n}\n</code></pre>"},{"location":"explanation/traits/#replication-state-methods","title":"Replication State Methods","text":"Method Purpose <code>get_table_replication_state()</code> Returns current phase for a table from cache <code>get_table_replication_states()</code> Returns phases for all tables from cache <code>load_table_replication_states()</code> Loads phases from persistent storage into cache. Call once at startup. Returns the number of states loaded <code>update_table_replication_state()</code> Updates phase in both cache and persistent storage <code>rollback_table_replication_state()</code> Reverts table to previous phase. Returns the phase after rollback"},{"location":"explanation/traits/#table-mapping-methods","title":"Table Mapping Methods","text":"<p>Table mappings connect source table IDs to destination table names.</p> Method Purpose <code>get_table_mapping()</code> Returns destination table name for a source table from cache <code>get_table_mappings()</code> Returns all mappings from cache <code>load_table_mappings()</code> Loads mappings from persistent storage into cache. Can be called lazily when needed <code>store_table_mapping()</code> Saves mapping to both cache and persistent storage"},{"location":"explanation/traits/#table-replication-phases","title":"Table Replication Phases","text":"<p>Tables progress through these phases:</p> Phase Persisted Description <code>Init</code> Yes Table discovered, ready to start <code>DataSync</code> Yes Initial data being copied <code>FinishedCopy</code> Yes Copy complete, waiting for coordination <code>SyncWait</code> No Table sync worker signaling apply worker to pause <code>Catchup { lsn }</code> No Apply worker paused, table sync worker catching up to LSN <code>SyncDone { lsn }</code> Yes Caught up to LSN, ready for handoff <code>Ready</code> Yes Streaming changes via apply worker <code>Errored { reason, solution, retry_policy }</code> Yes Error occurred, excluded until rollback"},{"location":"explanation/traits/#cleanupstore","title":"CleanupStore","text":"<p>Removes ETL metadata when tables are removed from the publication.</p> <pre><code>pub trait CleanupStore {\n    fn cleanup_table_state(&amp;self, table_id: TableId) -&gt; impl Future&lt;Output = EtlResult&lt;()&gt;&gt; + Send;\n}\n</code></pre> Method Purpose <code>cleanup_table_state()</code> Deletes all stored state for a table: replication state, schema, and mappings. Does not modify destination tables"},{"location":"explanation/traits/#combining-traits","title":"Combining Traits","text":"<p>A single type typically implements all store traits:</p> <pre><code>pub struct MyStore { /* ... */ }\n\nimpl SchemaStore for MyStore { /* ... */ }\nimpl StateStore for MyStore { /* ... */ }\nimpl CleanupStore for MyStore { /* ... */ }\n</code></pre> <p>ETL provides two built-in implementations:</p> <ul> <li><code>MemoryStore</code>: In-memory storage, not persistent across restarts</li> <li><code>PostgresStore</code>: Persistent storage backed by PostgreSQL</li> </ul>"},{"location":"explanation/traits/#thread-safety","title":"Thread Safety","text":"<p>All trait implementations must be thread-safe. ETL calls these methods concurrently from:</p> <ul> <li>Multiple table sync workers (parallel initial copy)</li> <li>Apply worker (streaming changes)</li> <li>Pipeline coordination</li> </ul> <p>Use <code>Arc&lt;Mutex&lt;_&gt;&gt;</code>, <code>RwLock</code>, or similar synchronization primitives for shared state.</p>"},{"location":"explanation/traits/#next-steps","title":"Next Steps","text":"<ul> <li>Custom Stores and Destinations: Implement these traits</li> <li>Event Types: Events received by <code>write_events()</code></li> <li>Architecture: How these components fit together</li> </ul>"},{"location":"guides/","title":"Guides","text":"<p>Step-by-step instructions to get things done</p>"},{"location":"guides/#available-guides","title":"Available Guides","text":"<ol> <li> <p>Configure Postgres: Set up your database for replication. Start here.</p> </li> <li> <p>Your First Pipeline (15 min): Build a pipeline that streams changes to memory.</p> </li> <li> <p>Custom Stores and Destinations (30 min): Implement your own store and HTTP destination.</p> </li> </ol>"},{"location":"guides/#before-you-start","title":"Before You Start","text":"<ul> <li>Rust 1.75 or later</li> <li>Postgres server (local or remote)</li> <li>Basic familiarity with Rust and SQL</li> </ul> <p>New to Postgres logical replication? Read Postgres Replication Concepts first.</p>"},{"location":"guides/#next-steps","title":"Next Steps","text":"<ul> <li>Architecture: Understand the internals</li> <li>Event Types: Learn about event data</li> <li>Extension Points: Customize ETL behavior</li> </ul>"},{"location":"guides/#need-help","title":"Need Help?","text":"<ol> <li>Double-check the prerequisites</li> <li>Search GitHub issues</li> <li>Open an issue with details</li> </ol>"},{"location":"guides/configure-postgres/","title":"Configure Postgres for Replication","text":"<p>Set up Postgres with the correct permissions and settings for ETL logical replication</p> <p>This guide covers the essential Postgres concepts and configuration needed for logical replication with ETL.</p>"},{"location":"guides/configure-postgres/#prerequisites","title":"Prerequisites","text":"<ul> <li>PostgreSQL 14, 15, 16, 17, or 18 (officially supported and tested versions)</li> <li>PostgreSQL 15+ recommended for advanced publication filtering (column-level, row-level, <code>FOR ALL TABLES IN SCHEMA</code>)</li> <li>PostgreSQL 14 supported with table-level filtering only</li> <li>Superuser access to the Postgres server</li> <li>Ability to restart Postgres (required for <code>wal_level</code> changes)</li> </ul>"},{"location":"guides/configure-postgres/#enable-logical-wal","title":"Enable Logical WAL","text":"<p>Set <code>wal_level = logical</code> to enable Postgres to record logical change data in the WAL, which external tools can then decode and stream.</p> <pre><code># postgresql.conf\nwal_level = logical\n</code></pre> <p>Restart Postgres after changing this setting.</p>"},{"location":"guides/configure-postgres/#replication-slots","title":"Replication Slots","text":"<p>Replication slots ensure Postgres retains WAL data for replication consumers, even if they disconnect temporarily. They are:</p> <ul> <li>Persistent markers that track replication progress</li> <li>WAL retention mechanisms that prevent cleanup until consumers catch up</li> <li>Consistency guarantees across disconnections</li> </ul>"},{"location":"guides/configure-postgres/#creating-replication-slots","title":"Creating Replication Slots","text":"<pre><code>-- Create a logical replication slot\nSELECT pg_create_logical_replication_slot('my_slot', 'pgoutput');\n</code></pre>"},{"location":"guides/configure-postgres/#viewing-replication-slots","title":"Viewing Replication Slots","text":"<pre><code>-- See all replication slots\nSELECT slot_name, slot_type, active, restart_lsn\nFROM pg_replication_slots;\n</code></pre>"},{"location":"guides/configure-postgres/#deleting-replication-slots","title":"Deleting Replication Slots","text":"<pre><code>-- Drop a replication slot when no longer needed\nSELECT pg_drop_replication_slot('my_slot');\n</code></pre> <p>Warning: Only delete slots when you are sure they are not in use. Deleting an active slot will break replication.</p>"},{"location":"guides/configure-postgres/#max-replication-slots","title":"Max Replication Slots","text":"<p>Controls how many replication slots Postgres can maintain simultaneously.</p> <pre><code># postgresql.conf (default is 10)\nmax_replication_slots = 20\n</code></pre> <p>ETL uses a single replication slot for its main apply worker. Additional slots are created for parallel table copies during initial sync or when new tables are added to the publication. The <code>max_table_sync_workers</code> pipeline parameter controls parallel copies, so total slots used by ETL never exceed <code>max_table_sync_workers + 1</code>.</p> <p>When to increase:</p> <ul> <li>Running multiple ETL pipelines against the same database</li> <li>Development/testing environments with frequent slot creation</li> </ul>"},{"location":"guides/configure-postgres/#max-wal-senders","title":"Max WAL Senders","text":"<p>Controls the maximum number of concurrent connections for streaming replication. Each replication slot uses one WAL sender connection.</p> <pre><code># postgresql.conf (default is 10)\nmax_wal_senders = 20\n</code></pre> <p>Set this to at least <code>max_replication_slots</code> to ensure all slots can connect.</p>"},{"location":"guides/configure-postgres/#wal-keep-size","title":"WAL Keep Size","text":"<p>Determines how much WAL data to retain on disk, providing a safety buffer for replication consumers.</p> <pre><code># postgresql.conf\nwal_keep_size = 1GB\n</code></pre> <p>This setting:</p> <ul> <li>Prevents WAL deletion when replication consumers fall behind</li> <li>Provides recovery time if ETL pipelines temporarily disconnect</li> <li>Balances disk usage with replication reliability</li> </ul>"},{"location":"guides/configure-postgres/#wal-buildup-and-disk-usage","title":"WAL Buildup and Disk Usage","text":"<p>Replication slots prevent Postgres from deleting WAL files until all consumers have processed them. This can cause significant disk usage if the pipeline falls behind or encounters errors.</p>"},{"location":"guides/configure-postgres/#common-causes-of-wal-buildup","title":"Common Causes of WAL Buildup","text":"<p>1. Tables in Errored State</p> <p>When a table enters an errored state, ETL keeps its replication slot active to maintain data consistency. This prevents WAL cleanup for that slot, causing Postgres to accumulate WAL files. If you have tables stuck in an errored state:</p> <ul> <li>Investigate and resolve the error cause</li> <li>Remove the table from the publication if no longer needed</li> <li>Increase available disk space as a temporary measure</li> </ul> <p>2. Slow Pipeline Performance</p> <p>If your destination cannot keep up with the rate of changes in Postgres, WAL will accumulate. Common scenarios:</p> <ul> <li>High destination latency (network or processing)</li> <li>Large transactions generating many changes at once</li> <li>Destination temporarily unavailable</li> </ul> <p>3. Long-Running Initial Table Copies</p> <p>During initial sync, ETL creates a replication slot for each table being copied. Large tables with millions of rows can take significant time to copy, during which Postgres continues accumulating WAL.</p> <p>Warning: If WAL grows beyond the configured limit, Postgres will terminate the replication slot. Control this with <code>max_slot_wal_keep_size</code>:</p> <pre><code># postgresql.conf\n# -1 = unlimited (dangerous for disk space)\nmax_slot_wal_keep_size = 10GB\n</code></pre> <p>If a slot is terminated due to exceeding this limit, ETL will restart the table sync from scratch.</p>"},{"location":"guides/configure-postgres/#monitoring-wal-usage","title":"Monitoring WAL Usage","text":"<pre><code>-- Check replication slot lag (how far behind each slot is)\nSELECT slot_name,\n       pg_wal_lsn_diff(pg_current_wal_lsn(), restart_lsn) AS lag_bytes,\n       pg_size_pretty(pg_wal_lsn_diff(pg_current_wal_lsn(), restart_lsn)) AS lag_pretty,\n       active\nFROM pg_replication_slots;\n\n-- Check total WAL directory size\nSELECT pg_size_pretty(sum(size)) AS wal_size\nFROM pg_ls_waldir();\n</code></pre>"},{"location":"guides/configure-postgres/#recommendations","title":"Recommendations","text":"<ul> <li>Set <code>max_slot_wal_keep_size</code> to a reasonable limit based on available disk space</li> <li>Monitor replication slot lag and alert when it exceeds acceptable thresholds</li> <li>Address errored tables promptly to prevent indefinite WAL accumulation</li> <li>Size initial sync workers appropriately (<code>max_table_sync_workers</code>) to balance parallelism with resource usage</li> </ul>"},{"location":"guides/configure-postgres/#publications","title":"Publications","text":"<p>Publications define which tables and operations to replicate.</p>"},{"location":"guides/configure-postgres/#creating-publications","title":"Creating Publications","text":"<pre><code>-- Create publication for specific tables\nCREATE PUBLICATION my_publication FOR TABLE users, orders;\n\n-- Create publication for all tables (use with caution)\nCREATE PUBLICATION all_tables FOR ALL TABLES;\n\n-- Include only specific operations\nCREATE PUBLICATION inserts_only FOR TABLE users WITH (publish = 'insert');\n</code></pre>"},{"location":"guides/configure-postgres/#partitioned-tables","title":"Partitioned Tables","text":"<p>To replicate partitioned tables, use <code>publish_via_partition_root = true</code>. This tells Postgres to treat the partitioned table as a single table for replication purposes. All changes to any partition are published as changes to the parent table:</p> <pre><code>-- Create publication with partitioned table support\nCREATE PUBLICATION my_publication FOR TABLE users, orders WITH (publish_via_partition_root = true);\n\n-- For all tables including partitioned tables\nCREATE PUBLICATION all_tables FOR ALL TABLES WITH (publish_via_partition_root = true);\n</code></pre> <p>Limitation: With this option enabled, <code>TRUNCATE</code> operations on individual partitions are not replicated. Execute truncates on the parent table instead:</p> <pre><code>-- This will NOT be replicated\nTRUNCATE TABLE orders_2024_q1;\n\n-- This WILL be replicated\nTRUNCATE TABLE orders;\n</code></pre>"},{"location":"guides/configure-postgres/#managing-publications","title":"Managing Publications","text":"<pre><code>-- View existing publications\nSELECT * FROM pg_publication;\n\n-- See which tables are in a publication\nSELECT * FROM pg_publication_tables WHERE pubname = 'my_publication';\n\n-- Add tables to existing publication\nALTER PUBLICATION my_publication ADD TABLE products;\n\n-- Remove tables from publication\nALTER PUBLICATION my_publication DROP TABLE products;\n\n-- Drop publication\nDROP PUBLICATION my_publication;\n</code></pre>"},{"location":"guides/configure-postgres/#version-specific-features","title":"Version-Specific Features","text":"<p>ETL supports PostgreSQL versions 14 through 18, with enhanced features available in newer versions:</p>"},{"location":"guides/configure-postgres/#postgresql-15-features","title":"PostgreSQL 15+ Features","text":"<p>Column-Level Filtering:</p> <pre><code>-- Replicate only specific columns from a table\nCREATE PUBLICATION user_basics FOR TABLE users (id, email, created_at);\n</code></pre> <p>Row-Level Filtering:</p> <pre><code>-- Replicate only rows that match a condition\nCREATE PUBLICATION active_users FOR TABLE users WHERE (status = 'active');\n</code></pre> <p>Schema-Level Publications:</p> <pre><code>-- Replicate all tables in a schema\nCREATE PUBLICATION schema_pub FOR ALL TABLES IN SCHEMA public;\n</code></pre>"},{"location":"guides/configure-postgres/#postgresql-14-limitations","title":"PostgreSQL 14 Limitations","text":"<p>PostgreSQL 14 supports table-level publication filtering only. Column-level and row-level filters are not available. Filter data at the application level if selective replication is required.</p>"},{"location":"guides/configure-postgres/#feature-compatibility-matrix","title":"Feature Compatibility Matrix","text":"Feature PostgreSQL 14 PostgreSQL 15+ Table-level publication Yes Yes Column-level filtering No Yes Row-level filtering No Yes <code>FOR ALL TABLES IN SCHEMA</code> No Yes Partitioned table support Yes Yes"},{"location":"guides/configure-postgres/#complete-configuration-example","title":"Complete Configuration Example","text":"<p>Minimal <code>postgresql.conf</code> setup:</p> <pre><code># Enable logical replication\nwal_level = logical\n\n# Replication capacity\nmax_replication_slots = 20\nmax_wal_senders = 20\n\n# WAL retention\nwal_keep_size = 1GB\n\n# Limit WAL retention per slot (optional but recommended)\nmax_slot_wal_keep_size = 10GB\n</code></pre> <p>After editing the configuration:</p> <ol> <li>Restart Postgres</li> <li>Create your publication:    <pre><code>CREATE PUBLICATION etl_publication FOR TABLE your_table;\n</code></pre></li> <li>Verify the setup:    <pre><code>SHOW wal_level;\nSHOW max_replication_slots;\nSELECT * FROM pg_publication WHERE pubname = 'etl_publication';\n</code></pre></li> </ol>"},{"location":"guides/configure-postgres/#next-steps","title":"Next Steps","text":"<ul> <li>Your First Pipeline: Hands-on tutorial using these settings</li> <li>Custom Stores and Destinations: Build your own components</li> <li>ETL Architecture: How ETL uses these settings</li> </ul>"},{"location":"guides/custom-implementations/","title":"Build Custom Stores and Destinations","text":"<p>30 minutes: Implement your own stores and destinations.</p> <p>Prerequisites: Completed Your First Pipeline or familiar with ETL basics.</p>"},{"location":"guides/custom-implementations/#understanding-the-destination-trait","title":"Understanding the Destination Trait","text":"<p>ETL delivers data to destinations in two phases:</p> Phase Method When Data Type Initial Copy <code>write_table_rows()</code> Startup <code>Vec&lt;TableRow&gt;</code> Streaming <code>write_events()</code> After copy <code>Vec&lt;Event&gt;</code> <p>Note: During initial copy, parallel table sync workers each process their own replication slot, so <code>Begin</code> and <code>Commit</code> transaction markers may appear multiple times. This does not duplicate actual row data.</p>"},{"location":"guides/custom-implementations/#step-1-create-the-project","title":"Step 1: Create the Project","text":"<pre><code>cargo new etl-custom --lib\ncd etl-custom\n</code></pre> <p>Update <code>Cargo.toml</code>:</p> <pre><code>[package]\nname = \"etl-custom\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n[[bin]]\nname = \"main\"\npath = \"src/main.rs\"\n\n[dependencies]\netl = { git = \"https://github.com/supabase/etl\" }\ntokio = { version = \"1.0\", features = [\"full\"] }\nreqwest = { version = \"0.11\", features = [\"json\"] }\nserde_json = \"1.0\"\ntracing = \"0.1\"\ntracing-subscriber = \"0.3\"\n</code></pre> <p>Verify: <code>cargo check</code> succeeds.</p>"},{"location":"guides/custom-implementations/#step-2-implement-a-custom-store","title":"Step 2: Implement a Custom Store","text":"<p>Create <code>src/custom_store.rs</code>. A store must implement three traits (see Extension Points for full details):</p> <ul> <li><code>SchemaStore</code> - Table schema storage and retrieval</li> <li><code>StateStore</code> - Replication progress and table mapping tracking</li> <li><code>CleanupStore</code> - Metadata cleanup when tables leave the publication</li> </ul> <pre><code>use std::collections::HashMap;\nuse std::sync::Arc;\nuse tokio::sync::Mutex;\nuse tracing::info;\n\nuse etl::error::EtlResult;\nuse etl::state::table::TableReplicationPhase;\nuse etl::store::cleanup::CleanupStore;\nuse etl::store::schema::SchemaStore;\nuse etl::store::state::StateStore;\nuse etl::types::{TableId, TableSchema};\n\n#[derive(Debug, Clone, Default)]\nstruct TableEntry {\n    schema: Option&lt;Arc&lt;TableSchema&gt;&gt;,\n    state: Option&lt;TableReplicationPhase&gt;,\n    mapping: Option&lt;String&gt;,\n}\n\n#[derive(Debug, Clone)]\npub struct CustomStore {\n    tables: Arc&lt;Mutex&lt;HashMap&lt;TableId, TableEntry&gt;&gt;&gt;,\n}\n\nimpl CustomStore {\n    pub fn new() -&gt; Self {\n        info!(\"Creating custom store\");\n        Self {\n            tables: Arc::new(Mutex::new(HashMap::new())),\n        }\n    }\n}\n\nimpl SchemaStore for CustomStore {\n    async fn get_table_schema(&amp;self, table_id: &amp;TableId) -&gt; EtlResult&lt;Option&lt;Arc&lt;TableSchema&gt;&gt;&gt; {\n        let tables = self.tables.lock().await;\n        Ok(tables.get(table_id).and_then(|e| e.schema.clone()))\n    }\n\n    async fn get_table_schemas(&amp;self) -&gt; EtlResult&lt;Vec&lt;Arc&lt;TableSchema&gt;&gt;&gt; {\n        let tables = self.tables.lock().await;\n        Ok(tables.values().filter_map(|e| e.schema.clone()).collect())\n    }\n\n    async fn load_table_schemas(&amp;self) -&gt; EtlResult&lt;usize&gt; {\n        Ok(0) // In-memory store, nothing to load\n    }\n\n    async fn store_table_schema(&amp;self, schema: TableSchema) -&gt; EtlResult&lt;()&gt; {\n        let mut tables = self.tables.lock().await;\n        let id = schema.id;\n        tables.entry(id).or_default().schema = Some(Arc::new(schema));\n        Ok(())\n    }\n}\n\nimpl StateStore for CustomStore {\n    async fn get_table_replication_state(\n        &amp;self,\n        table_id: TableId,\n    ) -&gt; EtlResult&lt;Option&lt;TableReplicationPhase&gt;&gt; {\n        let tables = self.tables.lock().await;\n        Ok(tables.get(&amp;table_id).and_then(|e| e.state.clone()))\n    }\n\n    async fn get_table_replication_states(\n        &amp;self,\n    ) -&gt; EtlResult&lt;HashMap&lt;TableId, TableReplicationPhase&gt;&gt; {\n        let tables = self.tables.lock().await;\n        Ok(tables\n            .iter()\n            .filter_map(|(id, e)| e.state.clone().map(|s| (*id, s)))\n            .collect())\n    }\n\n    async fn load_table_replication_states(&amp;self) -&gt; EtlResult&lt;usize&gt; {\n        Ok(0)\n    }\n\n    async fn update_table_replication_state(\n        &amp;self,\n        table_id: TableId,\n        state: TableReplicationPhase,\n    ) -&gt; EtlResult&lt;()&gt; {\n        info!(\"Table {} -&gt; {:?}\", table_id.0, state);\n        let mut tables = self.tables.lock().await;\n        tables.entry(table_id).or_default().state = Some(state);\n        Ok(())\n    }\n\n    async fn rollback_table_replication_state(\n        &amp;self,\n        _table_id: TableId,\n    ) -&gt; EtlResult&lt;TableReplicationPhase&gt; {\n        todo!(\"Implement rollback if needed\")\n    }\n\n    async fn get_table_mapping(&amp;self, table_id: &amp;TableId) -&gt; EtlResult&lt;Option&lt;String&gt;&gt; {\n        let tables = self.tables.lock().await;\n        Ok(tables.get(table_id).and_then(|e| e.mapping.clone()))\n    }\n\n    async fn get_table_mappings(&amp;self) -&gt; EtlResult&lt;HashMap&lt;TableId, String&gt;&gt; {\n        let tables = self.tables.lock().await;\n        Ok(tables\n            .iter()\n            .filter_map(|(id, e)| e.mapping.clone().map(|m| (*id, m)))\n            .collect())\n    }\n\n    async fn load_table_mappings(&amp;self) -&gt; EtlResult&lt;usize&gt; {\n        Ok(0)\n    }\n\n    async fn store_table_mapping(\n        &amp;self,\n        table_id: TableId,\n        mapping: String,\n    ) -&gt; EtlResult&lt;()&gt; {\n        let mut tables = self.tables.lock().await;\n        tables.entry(table_id).or_default().mapping = Some(mapping);\n        Ok(())\n    }\n}\n\nimpl CleanupStore for CustomStore {\n    async fn cleanup_table_state(&amp;self, table_id: TableId) -&gt; EtlResult&lt;()&gt; {\n        let mut tables = self.tables.lock().await;\n        tables.remove(&amp;table_id);\n        Ok(())\n    }\n}\n</code></pre> <p>Verify: <code>cargo check</code> succeeds.</p>"},{"location":"guides/custom-implementations/#step-3-implement-a-custom-destination","title":"Step 3: Implement a Custom Destination","text":"<p>Create <code>src/http_destination.rs</code>. A destination implements the <code>Destination</code> trait with four required methods:</p> <ul> <li><code>name()</code> - Return an identifier for logging</li> <li><code>truncate_table()</code> - Clear table before bulk load (called even if table does not exist)</li> <li><code>write_table_rows()</code> - Receive rows during initial copy (may receive empty vec for table creation)</li> <li><code>write_events()</code> - Receive streaming changes (batches may span multiple tables)</li> </ul> <p>There's also an optional <code>shutdown()</code> method with a default no-op implementation. Override it if your destination needs cleanup when the pipeline shuts down.</p> <pre><code>use reqwest::Client;\nuse serde_json::json;\nuse std::time::Duration;\nuse tracing::{info, warn};\n\nuse etl::destination::Destination;\nuse etl::error::{ErrorKind, EtlResult};\nuse etl::types::{Event, TableId, TableRow};\nuse etl::{bail, etl_error};\n\n#[derive(Debug, Clone)]\npub struct HttpDestination {\n    client: Client,\n    base_url: String,\n}\n\nimpl HttpDestination {\n    pub fn new(base_url: String) -&gt; EtlResult&lt;Self&gt; {\n        let client = Client::builder()\n            .timeout(Duration::from_secs(30))\n            .build()\n            .map_err(|e| etl_error!(ErrorKind::Unknown, \"HTTP client error\", source: e))?;\n        Ok(Self { client, base_url })\n    }\n\n    async fn post(&amp;self, path: &amp;str, body: serde_json::Value) -&gt; EtlResult&lt;()&gt; {\n        let url = format!(\"{}/{}\", self.base_url.trim_end_matches('/'), path);\n\n        for attempt in 1..=3 {\n            match self.client.post(&amp;url).json(&amp;body).send().await {\n                Ok(resp) if resp.status().is_success() =&gt; return Ok(()),\n                Ok(resp) if resp.status().is_client_error() =&gt; {\n                    bail!(ErrorKind::Unknown, \"Client error\", resp.status());\n                }\n                Ok(resp) =&gt; warn!(\"Attempt {}/3: status {}\", attempt, resp.status()),\n                Err(e) =&gt; warn!(\"Attempt {}/3: {}\", attempt, e),\n            }\n            if attempt &lt; 3 {\n                tokio::time::sleep(Duration::from_millis(500 * attempt as u64)).await;\n            }\n        }\n        bail!(ErrorKind::Unknown, \"Request failed after retries\");\n    }\n}\n\nimpl Destination for HttpDestination {\n    fn name() -&gt; &amp;'static str {\n        \"http\"\n    }\n\n    async fn truncate_table(&amp;self, table_id: TableId) -&gt; EtlResult&lt;()&gt; {\n        info!(\"Truncating table {}\", table_id.0);\n        self.post(&amp;format!(\"tables/{}/truncate\", table_id.0), json!({})).await\n    }\n\n    async fn write_table_rows(&amp;self, table_id: TableId, rows: Vec&lt;TableRow&gt;) -&gt; EtlResult&lt;()&gt; {\n        if rows.is_empty() {\n            return Ok(());\n        }\n        info!(\"Writing {} rows to table {}\", rows.len(), table_id.0);\n\n        let payload = json!({\n            \"table_id\": table_id.0,\n            \"rows\": rows.iter().map(|r| {\n                json!({ \"values\": r.values.iter().map(|v| format!(\"{:?}\", v)).collect::&lt;Vec&lt;_&gt;&gt;() })\n            }).collect::&lt;Vec&lt;_&gt;&gt;()\n        });\n\n        self.post(&amp;format!(\"tables/{}/rows\", table_id.0), payload).await\n    }\n\n    async fn write_events(&amp;self, events: Vec&lt;Event&gt;) -&gt; EtlResult&lt;()&gt; {\n        if events.is_empty() {\n            return Ok(());\n        }\n        info!(\"Writing {} events\", events.len());\n\n        let payload = json!({\n            \"events\": events.iter().map(|e| {\n                match e {\n                    Event::Insert(i) =&gt; json!({\"type\": \"insert\", \"table\": i.table_id.0}),\n                    Event::Update(u) =&gt; json!({\"type\": \"update\", \"table\": u.table_id.0}),\n                    Event::Delete(d) =&gt; json!({\"type\": \"delete\", \"table\": d.table_id.0}),\n                    Event::Begin(_) =&gt; json!({\"type\": \"begin\"}),\n                    Event::Commit(_) =&gt; json!({\"type\": \"commit\"}),\n                    Event::Relation(r) =&gt; json!({\"type\": \"relation\", \"table\": r.table_schema.id.0}),\n                    Event::Truncate(t) =&gt; json!({\"type\": \"truncate\", \"tables\": t.rel_ids}),\n                    Event::Unsupported =&gt; json!({\"type\": \"unsupported\"}),\n                }\n            }).collect::&lt;Vec&lt;_&gt;&gt;()\n        });\n\n        self.post(\"events\", payload).await\n    }\n}\n</code></pre> <p>Verify: <code>cargo check</code> succeeds.</p>"},{"location":"guides/custom-implementations/#step-4-wire-it-together","title":"Step 4: Wire It Together","text":"<p>Create <code>src/main.rs</code>:</p> <pre><code>mod custom_store;\nmod http_destination;\n\nuse custom_store::CustomStore;\nuse etl::config::{BatchConfig, PgConnectionConfig, PipelineConfig, TlsConfig};\nuse etl::pipeline::Pipeline;\nuse http_destination::HttpDestination;\nuse std::error::Error;\n\n#[tokio::main]\nasync fn main() -&gt; Result&lt;(), Box&lt;dyn Error&gt;&gt; {\n    tracing_subscriber::fmt::init();\n\n    let store = CustomStore::new();\n    let destination = HttpDestination::new(\"https://your-endpoint.example.com\".to_string())?;\n\n    let config = PipelineConfig {\n        id: 1,\n        publication_name: \"my_publication\".to_string(),\n        pg_connection: PgConnectionConfig {\n            host: \"localhost\".to_string(),\n            port: 5432,\n            name: \"your_database\".to_string(),\n            username: \"postgres\".to_string(),\n            password: Some(\"your_password\".to_string().into()),\n            tls: TlsConfig {\n                enabled: false,\n                trusted_root_certs: String::new(),\n            },\n            keepalive: None,\n        },\n        batch: BatchConfig {\n            max_size: 1000,\n            max_fill_ms: 5000,\n        },\n        table_error_retry_delay_ms: 10000,\n        table_error_retry_max_attempts: 5,\n        max_table_sync_workers: 4,\n    };\n\n    println!(\"Starting pipeline...\");\n    let mut pipeline = Pipeline::new(config, store, destination);\n    pipeline.start().await?;\n    pipeline.wait().await?;\n\n    Ok(())\n}\n</code></pre> <p>Note: Update the database name, password, and HTTP endpoint to match your setup.</p>"},{"location":"guides/custom-implementations/#step-5-test","title":"Step 5: Test","text":"<pre><code>cargo run\n</code></pre> <p>The pipeline will connect to Postgres and start replicating. You'll see your custom store logging state transitions and your destination receiving HTTP calls.</p>"},{"location":"guides/custom-implementations/#what-you-built","title":"What You Built","text":"<ul> <li>Custom Store - In-memory implementation of <code>SchemaStore</code>, <code>StateStore</code>, and <code>CleanupStore</code></li> <li>HTTP Destination - Forwards replicated data via HTTP POST with retry logic</li> <li>Working Pipeline - Connects your custom components to the ETL core</li> </ul>"},{"location":"guides/custom-implementations/#next-steps","title":"Next Steps","text":"<ul> <li>Extension Points - Full trait API documentation</li> <li>Event Types - Details on all events your destination receives</li> <li>Configure Postgres - Production database setup</li> <li>Architecture - How ETL works internally</li> </ul>"},{"location":"guides/first-pipeline/","title":"Build Your First ETL Pipeline","text":"<p>15 minutes: Learn the fundamentals by building a working pipeline.</p> <p>By the end of this tutorial, you'll have a complete ETL pipeline that streams data changes from Postgres to a memory destination in real-time.</p>"},{"location":"guides/first-pipeline/#what-youll-build","title":"What You'll Build","text":"<p>A real-time data pipeline that:</p> <ul> <li>Monitors a Postgres table for changes</li> <li>Streams INSERT, UPDATE, and DELETE operations</li> <li>Stores replicated data in memory for immediate access</li> </ul>"},{"location":"guides/first-pipeline/#prerequisites","title":"Prerequisites","text":"<ul> <li>Rust toolchain (1.75 or later)</li> <li>Postgres 14+ with logical replication enabled (<code>wal_level = logical</code> in <code>postgresql.conf</code>)</li> <li>Basic familiarity with Rust and SQL</li> </ul> <p>New to Postgres logical replication? Read Postgres Replication Concepts first.</p>"},{"location":"guides/first-pipeline/#step-1-create-the-project","title":"Step 1: Create the Project","text":"<pre><code>cargo new etl-tutorial\ncd etl-tutorial\n</code></pre> <p>Add dependencies to <code>Cargo.toml</code>:</p> <pre><code>[dependencies]\netl = { git = \"https://github.com/supabase/etl\" }\ntokio = { version = \"1\", features = [\"full\"] }\ntracing-subscriber = { version = \"0.3\", features = [\"env-filter\"] }\n</code></pre> <p>Verify: Run <code>cargo check</code> and confirm it compiles without errors.</p>"},{"location":"guides/first-pipeline/#step-2-set-up-postgres","title":"Step 2: Set Up Postgres","text":"<p>Connect to Postgres and create a test database:</p> <pre><code>CREATE DATABASE etl_tutorial;\n\\c etl_tutorial\n\nCREATE TABLE users (\n    id SERIAL PRIMARY KEY,\n    name TEXT NOT NULL,\n    email TEXT UNIQUE NOT NULL,\n    created_at TIMESTAMP DEFAULT NOW()\n);\n\nINSERT INTO users (name, email) VALUES\n    ('Alice Johnson', 'alice@example.com'),\n    ('Bob Smith', 'bob@example.com');\n\nCREATE PUBLICATION my_publication FOR TABLE users;\n</code></pre> <p>Verify: <code>SELECT * FROM pg_publication WHERE pubname = 'my_publication';</code> returns one row.</p>"},{"location":"guides/first-pipeline/#step-3-write-the-pipeline","title":"Step 3: Write the Pipeline","text":"<p>Replace <code>src/main.rs</code>:</p> <pre><code>use etl::config::{BatchConfig, PgConnectionConfig, PipelineConfig, TlsConfig};\nuse etl::pipeline::Pipeline;\nuse etl::store::both::memory::MemoryStore;\nuse etl_destinations::bigquery::BigQueryDestination;\nuse std::error::Error;\n\n#[tokio::main]\nasync fn main() -&gt; Result&lt;(), Box&lt;dyn Error&gt;&gt; {\n    let pg_config = PgConnectionConfig {\n        host: \"localhost\".to_string(),\n        port: 5432,\n        name: \"etl_tutorial\".to_string(),\n        username: \"postgres\".to_string(),\n        password: Some(\"your_password\".to_string().into()),  // Update this\n        tls: TlsConfig {\n            enabled: false,\n            trusted_root_certs: String::new(),\n        },\n        keepalive: None,\n    };\n\n    let config = PipelineConfig {\n        id: 1,\n        publication_name: \"my_publication\".to_string(),\n        pg_connection: pg_config,\n        batch: BatchConfig {\n            max_size: 1000,\n            max_fill_ms: 5000,\n        },\n        table_error_retry_delay_ms: 10000,\n        table_error_retry_max_attempts: 5,\n        max_table_sync_workers: 4,\n    };\n\n    let store = MemoryStore::new();\n    let destination = BigQueryDestination::new_with_key_path(\n        \"my-gcp-project\".into(),\n        \"my_dataset\".into(),\n        \"/path/to/service-account-key.json\",\n        None,\n        1,\n        1,\n        store.clone(),\n    )\n    .await?;\n\n    println!(\"Starting pipeline...\");\n    let mut pipeline = Pipeline::new(config, store, destination);\n    pipeline.start().await?;\n    pipeline.wait().await?;\n\n    Ok(())\n}\n</code></pre> <p>Note: Update the <code>password</code> field to match your Postgres credentials.</p>"},{"location":"guides/first-pipeline/#step-4-run-the-pipeline","title":"Step 4: Run the Pipeline","text":"<pre><code>RUST_LOG=info cargo run\n</code></pre> <p>You should see the initial table data being copied (the two users from Step 2), then the pipeline continues running, waiting for changes.</p>"},{"location":"guides/first-pipeline/#step-5-test-real-time-replication","title":"Step 5: Test Real-Time Replication","text":"<p>In another terminal, make changes to the database:</p> <pre><code>\\c etl_tutorial\n\nINSERT INTO users (name, email) VALUES ('Charlie Brown', 'charlie@example.com');\nUPDATE users SET name = 'Alice Cooper' WHERE email = 'alice@example.com';\nDELETE FROM users WHERE email = 'bob@example.com';\n</code></pre> <p>Your pipeline terminal should show these changes being captured in real-time.</p>"},{"location":"guides/first-pipeline/#cleanup","title":"Cleanup","text":"<p>Stop the pipeline with <code>Ctrl+C</code>, then clean up the database:</p> <pre><code>-- Connect to a different database first (e.g., postgres)\n\\c postgres\nDROP DATABASE etl_tutorial;\n</code></pre>"},{"location":"guides/first-pipeline/#what-you-learned","title":"What You Learned","text":"<ul> <li>Publications define which tables to replicate via Postgres logical replication</li> <li>Pipeline configuration controls batching behavior and error retry policies</li> <li>Memory destinations store data in-memory, useful for testing and development</li> <li>The pipeline performs an initial table copy, then streams changes in real-time</li> </ul>"},{"location":"guides/first-pipeline/#next-steps","title":"Next Steps","text":"<ul> <li>Custom Stores and Destinations: Build your own components</li> <li>Configure Postgres: Production Postgres setup</li> <li>Architecture: How ETL works internally</li> </ul>"}]}